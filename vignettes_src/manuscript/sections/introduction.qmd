
# Introduction
As pharmacology experiments increase in complexity, it becomes increasingly challenging to analyze them. While there are many frameworks for fitting common curves in pharmacology ranging from the user friendly GraphPad Prism, the \texttt{drc} dose response curves \texttt{R} package\ref{}, to generic \texttt{nlm} packages, a principled approach is to use Bayesian statistics to quantify model uncertainty before and after collecting data. In practice this requires defining a functional form, a prior distribution over the model parameters, and likelihood function that models the data generation process. Then using Markov Chain Monte-Carlo (MCMC) or variational inference the prior and the likelihood are combined to generate samples from the posterior distribution over the parameters. 

Excitingly, there has been rapid progress in developing computational frameworks to facilitate developing and applying Bayesian models. A key example is the Stan ecosystem, which defines a model description language, inference engines, front-end interfaces to many common languages, and a suite of tools to analyze fit models ([@Carpenter2017-pj, @Burkner2017-ww, @Vehtari2017-pw, @Gabry2017-jm, @Kay2018-kn, @Wickham2016-xy, @Wickham2019-jb, @Team2013-nq). To facilitate rapid application model development, the Bayesian Regression Modeling using Stan (BRMS) package in R implements a formula-based interface for Stan similar to \texttt{lme4}, that support defining linear and nonlinear predictors, hierarchical models, and a range of pre-specified or custom response functions. Once specified these models are translated into the Stan modeling language, where they are compiles and run.  

Here we describe the BayesPharma R package, a novel Bayesian pharmacology modeling framework building on the \texttt{Stan} and \texttt{BRMS}. After reviewing basic Bayesian modeling concepts in the context of dose-response experiments, we will describe the package architecture and demonstrate the utility through several case studies.

# Bayesian Modeling Workflow {#workflow}
The scientific method can be conceptualized through building and analyzing models. Consider we are interested in interacting with a complex system such as an rocket ship, ecosystem, person with an illness etc., but we are cautious because doing so may be dangerous, expensive, slow, or unethical. Therefore we may develop a tractable model system to interact with instead (such as a very small rocket ship, zebrafish, or molecular simulation, etc.). If the model system corresponds with to the system of interest in relevant ways, then poking and prodding the model system can be use to anticipate how the system of interest will respond when it is in turn poked and prodded. A key step in establishing this correspondence is to collect a small amount of data from the system of interest and use it design the model system to be representative.

When scientific model systems are constructed by composing conditional probability distributions, they are often called Bayesian models. This is because the key step of going from a nebulous set of possible models to more precise set of models based on observed data uses the celebrated Bayes theorem. While basic Bayesian theory is covered in range of introductory and advanced textbooks. To complement those totally reasonable expositions, here we will correct, but informal derivation of Bayesian probability, to helpfully build intuition and facilitate communication with practitioners. Let $\theta \in \Theta$ be a vector of model parameters and let $\mbox{D} \in \mathbb{D}$ observed data. For concreteness, you can think of $\theta = \left(\mbox{Top}, \mbox{Bottom}, \mbox{IC}_{\mbox{50}}, \mbox{Slope}\right)$ as the parameters for specific sigmoid function, and $\mbox{D}=\{(\mbox{dose}_i, \mbox{response}_i)_{i\in N}\}$, a set of dose-response measurements. A probability distribution naturally models an event or an occurrence. The event is sometimes called a random variable.  Given a region, the chance that the event happens in that region is the probability density over it. Assuming the event definitely happens, then the total density must integrate to unity. A joint distribution over two random variables is just the probability that both events occur.  A conditional probability distribution can be thought of as a stochastic function, where evaluation corresponds to setting the values to be conditioned and obtaining the remaining values. Concretely if you have a scatter plot, you could sample points by first sampling along the x-axis and within the narrow range of the chosen x-value, pick a y-value. Or visa versa, first sample along the y-axis and then within the narrow range of the chose y-value, pick the x-value. Then the joint probability distribution over parameters and data, $P(\theta, D)$ can be written as conditional probability distributions two different ways, $P(\theta | D)P(D)$, and $P(D | \theta)P(\theta)$. Setting them equal to each other and dividing through by $P(D)$ gives Bayes Theorem:
$$
    P(\theta | D) = \frac{P(D | \theta)P(\theta)}{P(D)}.
$$
With that in mind, lets look at each term in the is equation. The easiest is the $P(\theta)$, this called the prior must be specified before hand. We'll come back to how to chose priors below. The term $P(D | \theta)$ is called the likelihood, and can thought of as the data generation process, the "model system" if you will. On the left is the $P(\theta | D)$, which is called the posterior. This is a little trickier to understand, but thinking of it as a stochastic function, we can at least inspect the signature: it takes in data, and produces random samples of parameters. Finally the $P(D)$ is called the evidence, and is basically there to make the left and the right be equal to each other. As we'll see below, we don't actually need to evaluate it, but if did we could use a trick called marginalization.

How do we sample parameter values from the posterior distribution? One way to conceptualize problem is to use Boltzmann's equation to convert the probability distribution to an energy function and temperature. Then to sample, begin at a location in parameter space and simulate the kinematic trajectory as it would move through the parameter space over time. Given enough time, if the parameter can access all parts of the probability distribution, the parameter will equilibrate and give sample from the probability distribution. While this is guaranteed to happen eventually, in practice a common concern is that for any fixed amount of equilibration, it is unclear if there has been sufficient mixing. We'll come back to strategies to detect and handle issues with mixing below. A basic kinematic sampling algorithm called Markov Chain Monte Carlo (MCMC) says to take a step, and if it has lower energy, accept, if it has higher energy accept with a probability proportional to the difference in probabilities between the two states and the simulation temperature. A key insight is that because only relative probabilities are needed, the global evidence normalization factors cancel and therefore they don't even need to be computed. More sophisticated algorithms take into account the not only the specific energy values but also the energy gradient. Thinking of the object as having inertia, the sampling allows it to overcome certain types of local minima. to take steps that are likely to be accepted, sometimes called Hamiltonian Monte Carlo. A particularly annoying pat of HMC is that in some cases, such as a narrow ravine in the energy landscape, the trajectory will vibrate back and forth without making much forward progress. A clever heuristic that is used by the Stan, called No U-turn sampling (NUTs), tries to dampen these types of unproductive moves.     

The principled Bayesian workflow [@Gelman2020-sf, @Van_de_Schoot2020-ei], describes a general protocol building robust Bayesian models and using them to draw inferences. The main steps involve
\begin{enumerate}
\item Define and fit a probabilistic model, which combines a *prior* distribution over a set of parameters with the data to draw samples from *posterior* distribution over the parameters using Hamiltonian Markov Chain Monte Carlo.
\item Check for sampling convergence.
\item Use prior and posterior predictive checks to evaluate the model specification and fit.
\item Use cross validation to evaluate the generalizability of the model.
\item Assess inferences that can be made from the model.
\end{enumerate}


## Model selection {#model_selection}

(Vehtari, 2016, https://arxiv.org/abs/1507.04544)
predictive accuracy
   how well would the model generalize to new data?
   empirical risk minimization of the model log-likelihood
   leave-k-out cross validation
      - expensive to re-fit model k times
      - approximation via importance sampling but may be unstable
      - Pareto smoothed importance sampling (PSIS) more stable


# BayesPharma package design {#package_design}
We designed the BayesPharma package to support modeling of foundational pharmacology models using the principle Bayesian workflow. As described above, the workflow involves four phases: model specification, model fitting, model evaluation, and interpretation. Here we will describe the BayesPharma API and how we recommend using it. 

To provide data to the BayesPharma package, the user provides a R \texttt{data.frame} with columns \texttt{response}, \mbox{log\_dose}, optionally additional covariates such as \texttt{drug\_id} or \texttt{batch\_id}. To specify the model involves specifying the (1) the formulate relating the predictors to the response, (2) the family (3) priors over the model parameters (4) initial values, and (5) additional arguments to tune sampling.
