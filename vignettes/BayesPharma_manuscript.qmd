---
title: "BayesPharma: Bayesian methods for pharmacology models"
format:
  jss-pdf:
    keep-tex: true  
  jss-html: default
author:
  - name: Madeline J. Martin
    email: martin.mjm105@gmail.com
    affiliations:
      - ref: knight
  - name: Elayne Vieira Diaz
    email: Elayne.Vieiradias@ucsf.edu
    affiliations:
      - ref: weill
  - name: P. Walter German
    email: p.walter.german@gmail.com
    affiliations:
      - ref: weill
  - name: Elyssa B. Margolis
    email: elyssa.margolis@ucsf.edu
    orcid: 0000-0001-8777-302X
    affiliations:
      - ref: weill
      - ref: ucsf_ngp
  - name: Matthew J. O'Meara
    email: maom@umich.edu
    orcid: 0000-0002-3128-5331
    attributes:
      corresponding: true
    affiliations:
      - ref: dcmb
affiliations:
  - id: knight
    name: University of Oregon
    department: Knight Campus Center for Accelerating Scientific Impact
    city: Eugene
    state: OR
    postal-code: 97403
    country: USA
  - id: weill
    name: University of California, San Francisco
    department: UCSF Weill Institute for Neurosciences, Department of Neurology 
    city: San Francisco
    state: CA
    postal-code: 94158
    country: USA
  - id: ucsf_ngp
    name: University of California, San Francisco
    department: Neuroscience Graduate Program
    city: San Francisco
    state: CA
    country: USA
  - id: dcmb
    name: University of Michigan
    department: Department of Computational Medicine and Bioinformatics
    city: Ann Arbor
    state: MI
    country: USA
abstract: |
  In pharmacology, many experiments seek to measure how a reductive biological
  system responds to one or more treatments. Here we present BayesPharma, a
  collection of Bayesian methods to help analyze these experiments. BayesPharma
  is an \texttt{R} package to facilitate applying a principled Bayesian workflow
  to analyze pharmacology data, built around the \texttt{Stan} ecosystem.
  BayesPharma can be used out of the box to fit and analyze several foundational
  pharmacology models; as a pedagogical framework for learning Bayesian methods;
  and as a starting point for building and analyzing sophisticated
  pharmacological models.  
bibliography: references.bib
editor: visual
header-includes: |
  % https://colorbrewer2.org/#type=qualitative&scheme=Dark2&n=3
  \definecolor{dose}{rgb}{0.10546875,0.6171875,0.46484375}
  \definecolor{response}{rgb}{0.8476562,0.3710938,0.0078125}
  \definecolor{shape}{rgb}{0.4570312,0.4375000,0.6992188}
knitr:
  opts_knit:
    verbose: true
  opts_chunk: 
    cache: true
    echo: false
    fit.path: "BayesPharma_manuscript/quarto-"
    fig.width: 6
    fig.height: 5
    fig.pos: "t"
    fig.align: "center"
    out.width: "100%"

keywords: [Bayesian, Pharmacology, R]
keywords-formatted: [Bayesian, Pharmacology, "[R]{.proglang}"]
---
```{r set-options}
#| echo=FALSE
# inspired by https://www.jumpingrivers.com/blog/knitr-default-options-settings-hooks/
knitr::opts_chunk$set(
  dpi = if (knitr::is_latex_output()) 72 else 300)
#  dev = "svg",
#  dev.args = list(png = list(type = "cairo-png")),
#  optipng = "-o1 -quiet")
# cmdstanr is more up-to-date than rstan and runs a little faster
# but can't expose defined functions for downstream analysis
if(Sys.info()["machine"] == "arm64"){
  #rstan does not currently support apple M1 chips
  stan_backend <- "cmdstanr"
} else {
  stan_backend <- "rstan"
}
```

```{r load-packages}
library(tidyverse)
library(BayesPharma)
library(drc)
library(brms)
library(broom)
```


# Introduction
As pharmacology experiments increase in complexity, it becomes increasingly challenging to analyze them. While there are many frameworks for fitting common curves in pharmacology ranging from the user friendly GraphPad Prism, the \texttt{drc} dose response curves \texttt{R} package\ref{}, to generic \texttt{nlm} packages, a principled approach is to use Bayesian statistics to quantify model uncertainty before and after collecting data. In practice this requires defining a functional form, a prior distribution over the model parameters, and likelihood function that models the data generation process. Then using Markov Chain Monte-Carlo (MCMC) or variational inference the prior and the likelihood are combined to generate samples from the posterior distribution over the parameters. 

Excitingly, there has been rapid progress in developing computational frameworks to facilitate developing and applying Bayesian models. A key example is the Stan ecosystem, which defines a model description language, inference engines, front-end interfaces to many common languages, and a suite of tools to analyze fit models ([@Carpenter2017-pj, @Burkner2017-ww, @Vehtari2017-pw, @Gabry2017-jm, @Kay2018-kn, @Wickham2016-xy, @Wickham2019-jb, @Team2013-nq). To facilitate rapid application model development, the Bayesian Regression Modeling using Stan (BRMS) package in R implements a formula-based interface for Stan similar to \texttt{lme4}, that support defining linear and nonlinear predictors, hierarchical models, and a range of pre-specified or custom response functions. Once specified these models are translated into the Stan modeling language, where they are compiles and run.  

Here we describe the BayesPharma R package, a novel Bayesian pharmacology modeling framework building on the \texttt{Stan} and \texttt{BRMS}. After reviewing basic Bayesian modeling concepts in the context of dose-response experiments, we will describe the package architecture and demonstrate the utility through several case studies.

# Bayesian Modeling Workflow {#workflow}
The scientific method can be conceptualized through building and analyzing models. Consider we are interested in interacting with a complex system such as an rocket ship, ecosystem, person with an illness etc., but we are cautious because doing so may be dangerous, expensive, slow, or unethical. Therefore we may develop a tractable model system to interact with instead (such as a very small rocket ship, zebrafish, or molecular simulation, etc.). If the model system corresponds with to the system of interest in relevant ways, then poking and prodding the model system can be use to anticipate how the system of interest will respond when it is in turn poked and prodded. A key step in establishing this correspondence is to collect a small amount of data from the system of interest and use it design the model system to be representative.

When scientific model systems are constructed by composing conditional probability distributions, they are often called Bayesian models. This is because the key step of going from a nebulous set of possible models to more precise set of models based on observed data uses the celebrated Bayes theorem. While basic Bayesian theory is covered in range of introductory and advanced textbooks. To complement those totally reasonable expositions, here we will correct, but informal derivation of Bayesian probability, to helpfully build intuition and facilitate communication with practitioners. Let $\theta \in \Theta$ be a vector of model parameters and let $\mbox{D} \in \mathbb{D}$ observed data. For concreteness, you can think of $\theta = \left(\mbox{Top}, \mbox{Bottom}, \mbox{IC}_{\mbox{50}}, \mbox{Slope}\right)$ as the parameters for specific sigmoid function, and $\mbox{D}=\{(\mbox{dose}_i, \mbox{response}_i)_{i\in N}\}$, a set of dose-response measurements. A probability distribution naturally models an event or an occurrence. The event is sometimes called a random variable.  Given a region, the chance that the event happens in that region is the probability density over it. Assuming the event definitely happens, then the total density must integrate to unity. A joint distribution over two random variables is just the probability that both events occur.  A conditional probability distribution can be thought of as a stochastic function, where evaluation corresponds to setting the values to be conditioned and obtaining the remaining values. Concretely if you have a scatter plot, you could sample points by first sampling along the x-axis and within the narrow range of the chosen x-value, pick a y-value. Or visa versa, first sample along the y-axis and then within the narrow range of the chose y-value, pick the x-value. Then the joint probability distribution over parameters and data, $P(\theta, D)$ can be written as conditional probability distributions two different ways, $P(\theta | D)P(D)$, and $P(D | \theta)P(\theta)$. Setting them equal to each other and dividing through by $P(D)$ gives Bayes Theorem:
$$
    P(\theta | D) = \frac{P(D | \theta)P(\theta)}{P(D)}.
$$
With that in mind, lets look at each term in the is equation. The easiest is the $P(\theta)$, this called the prior must be specified before hand. We'll come back to how to chose priors below. The term $P(D | \theta)$ is called the likelihood, and can thought of as the data generation process, the "model system" if you will. On the left is the $P(\theta | D)$, which is called the posterior. This is a little trickier to understand, but thinking of it as a stochastic function, we can at least inspect the signature: it takes in data, and produces random samples of parameters. Finally the $P(D)$ is called the evidence, and is basically there to make the left and the right be equal to each other. As we'll see below, we don't actually need to evaluate it, but if did we could use a trick called marginalization.

How do we sample parameter values from the posterior distribution? One way to conceptualize problem is to use Boltzmann's equation to convert the probability distribution to an energy function and temperature. Then to sample, begin at a location in parameter space and simulate the kinematic trajectory as it would move through the parameter space over time. Given enough time, if the parameter can access all parts of the probability distribution, the parameter will equilibrate and give sample from the probability distribution. While this is guaranteed to happen eventually, in practice a common concern is that for any fixed amount of equilibration, it is unclear if there has been sufficient mixing. We'll come back to strategies to detect and handle issues with mixing below. A basic kinematic sampling algorithm called Markov Chain Monte Carlo (MCMC) says to take a step, and if it has lower energy, accept, if it has higher energy accept with a probability proportional to the difference in probabilities between the two states and the simulation temperature. A key insight is that because only relative probabilities are needed, the global evidence normalization factors cancel and therefore they don't even need to be computed. More sophisticated algorithms take into account the not only the specific energy values but also the energy gradient. Thinking of the object as having inertia, the sampling allows it to overcome certain types of local minima. to take steps that are likely to be accepted, sometimes called Hamiltonian Monte Carlo. A particularly annoying pat of HMC is that in some cases, such as a narrow ravine in the energy landscape, the trajectory will vibrate back and forth without making much forward progress. A clever heuristic that is used by the Stan, called No U-turn sampling (NUTs), tries to dampen these types of unproductive moves.     

The principled Bayesian workflow [@Gelman2020-sf, @Van_de_Schoot2020-ei], describes a general protocol building robust Bayesian models and using them to draw inferences. The main steps involve
\begin{enumerate}
\item Define and fit a probabilistic model, which combines a *prior* distribution over a set of parameters with the data to draw samples from *posterior* distribution over the parameters using Hamiltonian Markov Chain Monte Carlo.
\item Check for sampling convergence.
\item Use prior and posterior predictive checks to evaluate the model specification and fit.
\item Use cross validation to evaluate the generalizability of the model.
\item Assess inferences that can be made from the model.
\end{enumerate}

# BayesPharma package design {#package_design}
We designed the BayesPharma package to support modeling of foundational pharmacology models using the principle Bayesian workflow. As described above, the workflow involves four phases: model specification, model fitting, model evaluation, and interpretation. Here we will describe the BayesPharma API and how we recommend using it. 

To provide data to the BayesPharma package, the user provides a R \texttt{data.frame} with columns \texttt{response}, \mbox{log\_dose}, optionally additional covariates such as \texttt{drug\_id} or \texttt{batch\_id}. To specify the model involves specifying the (1) the formulate relating the predictors to the response, (2) the family (3) priors over the model parameters (4) initial values, and (5) additional arguments to tune sampling.

# Case Studies
In this section we will consider several models as case studies: the sigmoidal hill model in #{sec:hill}, the MuSyC synergy model in {#sec:MuSyC}, Michaelis-Menten enzyme progress curve in #{sec:michaelis_menten}. For each we will implement it, and apply it to example data by fitting different models and then we will compare the models based on their fit of the data and inferences that can be made.

## Hill Equation {#hill}
In this case study we are going to reanalyze the dose response of 4 Kappa Opioid 
receptor (KOR) antagonists using the `BayesPharma` package from from a study 
done by Margolis et al. (-@Margolis2020-bm). Whole cell electrophysiology in acute rat midbrain slices was used to evaluate pharmacological properties of four novel KOR antagonists: BTRX-335140, BTRX-395750, PF-04455242, and JNJ-67953964

Originally paper, the dose-response data analysis was done by using the `drc` package in R which implements the minimization of negative log likelihood function and reduces to least square estimation for a continuous response. The data was normalized to % baseline then fit to a 4-parameter log-logistic dose response model, setting the top (max response) to 100% and estimating the IC50, its variance, and the bottom (min response).

### Fitting the sigmoid model
Using the BayesPharma package, we can re-fit the sigmoid model with a negative slope, and fixing the top parameter to 100 as the response is normalized to a no-drug baseline.

For the priors, we are going to use a normal distribution because the response
values are continuous. First, We will run the analysis with top (max response) parameter prior set to a constant value of 100 because top is normalized to 100 and the default broad
priors for ic50, hill and bottom. Broad priors represent unbiased uncertainty and provide an opportunity for extreme responses.

The level of informativeness of the priors will affect how much influence the priors have on the model. Here is more [information on prior choice recommendations.](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)
\scriptsize
```{r kor-priors}
#| echo=TRUE
kor_priors <- BayesPharma::dr_priors(inhibitor = TRUE, top = 100)
kor_priors
```
\normalsize

#### Prior predictive checks
Following the Bayesian workflow, before fitting the model it is good to check the prior predictive distributions to see if they are compatible with the domain expertise. So, before running the model, we will verify that the prior distributions cover a plausible range of values for each parameter. To do this, we want to  sample only from the prior distributions by adding  *sample_prior = "only"* as  an argument to the `dr_model` function. We will use the default response distribution of the model  (*family = gaussian()*).


```{r kor-data}
load("/Users/maom/opt/BayesPharma/data/kor_antag.rda")
kor_antag <- kor_antag |> dplyr::transmute(
  substance_id = Drug,
  cell_id = cell_number,
  log_dose = log_dose,
  response = normalized_measurement)
```

\scriptsize
```{r kor-prior-sample}
#| echo=TRUE,
#| results='hide',
#| message=FALSE,
#| dependson=c("kor-priors")

kor_sample_priors <- BayesPharma::dr_model(
  data = kor_antag |> dplyr::select(substance_id, log_dose, response),
  BayesPharma::dr_formula(), 
  priors = kor_priors,
  sample_prior = "only")
```
\normalsize

And then plot of the prior predictive distributions:

\scriptsize
```{r kor-prior-density-plot}
#| echo=TRUE,
#| results='show',
#| dependson=c("kor-prior-sample"),
#| fig.width = 9,
#| fig.height = 2.6,
#| fig.cap="KOR antagonists prior distribution"

BayesPharma::density_distributions(
  kor_sample_priors, 
  half_max_label = "ic50",
  title_label = "") +
  ggplot2::facet_wrap(
    facets = dplyr::vars(.variable),
    scales = "free",
    nrow = 1)
```
\normalsize

To sample from the model we will the Stan NUTs Hamiltonian Monte Carlo, and initialize the parameters to the prior means to help with model convergence, using the default values of ec50 = -9, hill = -1, top = 100, bottom = 0.

\scriptsize
```{r kor-model}
#| echo=TRUE,
#| dependson = c("kor-data"),
#| results='hide',
#| message=FALSE
kor_model <- BayesPharma::dr_model(
  data = kor_antag |> dplyr::select(substance_id, log_dose, response),
  formula = BayesPharma::dr_formula(predictors = 0 + substance_id), 
  priors = kor_priors,
  init = BayesPharma::dr_inits())
brms::expose_functions(kor_model, vectorize=TRUE)
```
\normalsize

### Analyzing model fit
The BRMS generated model summary shows the formula that the expected response is sigmoid function of the log_dose with four parameters, and a shared Gaussian distribution. Each parameter is dependent on the substance_id. Since want to fit a separate model for each substance we include a `0 +` to indicate that there is no common intercept.  The consists of 73 data points and the posterior sampling was done in 4 chains each with 8000 steps with 4000 steps of warm-up. The population effects for each parameter summarize marginal posterior distributions, as well as the effective sample size in the bulk and tail. This gives an indication of the sampling quality, with an ESS of > 500 samples being good for this type of model. 
\scriptsize
```{r kor-model-summary}
#| dependson=c("kor-model"),
#| R.options = list(width = 350)
kor_model
```
\normalsize

#### Traceplot
The model ran without warning messages meaning there were no parameter value 
problems or mcmc conflicts. The bulk and tail ESS indicate high resolution and 
stability. The R-hat for each parameter equals 1.00 and the traceplot shows the 
chains mixed well indicating the chains converged.

\scriptsize
```{r kor-model-traceplot}
#| echo=TRUE,
#| fig.height=6,
#| fig.width=12,
#| dependson=c("kor-model")

BayesPharma::traceplot(
  kor_model, 
  predictors_col_name = "substance_id", 
  half_max_label = "ic50") 
```
\normalsize

#### Compare prior and posterior marginal distributions
Displayed below is a plot for the prior and posterior distributions of the  parameters (prior is pink and posterior is teal). this can be useful for  comparing the density distribution of the prior and posterior. produced by the model:

\scriptsize
```{r kor-model-prior-posterior-densities}
#| dependson=c("kor-model"),
#| echo=TRUE,
#| results='hide',
#| message=FALSE,
#| fig.width = 9,
#| fig.height = 5,
#| fig.cap="KOR antagonists model, compare prior and posterior distributions for each substance"

BayesPharma::prior_posterior_densities(
  kor_model,
  predictors_col_name = "substance_id",
  half_max_label = "ic50",
  title_label="")
```
\normalsize
Displayed below is a plot of the posterior distributions for each parameter 
with the confidence intervals and mean. This is a useful visual of the model 
results and to highlight the mode and high density intervals: 
  
```{r kor-model-posterior-densities}
#| dependson=c("kor-model"),
#| echo=TRUE,
#| message=FALSE,
#| warning=FALSE,
#| fig.width=9,
#| fig.height=5,
#| fig.cap="KOR Antagonists, posterior distribution for each substance"

BayesPharma::posterior_densities(
  kor_model, 
  predictors_col_name = "substance_id", 
  half_max_label = "ic50",
  title_label = "")
```

Displayed below is a plot of a sample of 100 sigmoid dose-response curves from 
the posterior distribution (purple) and the median quantile intervals: 

```{r kor-model-posterior-draws}
#| echo=TRUE,
#| results='hide',
#| message=FALSE,
#| warning=FALSE,
#| dependson=c("kor-model"),
#| fig.cap="KOR antagonists, posterior draws"

BayesPharma::posterior_draws_plot(
  model = kor_model,
  predictors_col_name = "substance_id",
  lower = -12,
  upper = -4,
  n = 50, 
  facet_var = substance_id,
  title = "",
  xlab = "Log[Molar]",
  ylab = "Response")
```

### Comparing alternative models

To test the sensitivity of the analysis to the priors, we can re-fit the model with more informative priors:
\scriptsize
```{r kor-model-priors2}
kor_priors2 <- BayesPharma::dr_priors(
  ec50 = brms::prior(normal(-8.5, 0.5), nlpar = "ec50"),
  hill = brms::prior(normal(-1, 0.5), ub = 0.01, nlpar = "hill"),
  top = 100,
  bottom = brms::prior(normal(10, 15), nlpar = "bottom"))
kor_priors2
```
\normalsize

Re-fitting the model

\scriptsize
```{r kor-model2}
#| results='hide',
#| message=FALSE,
#| dependson=c("kor-model-priors2")

kor_model2 <- BayesPharma::dr_model(
  data = kor_antag |> dplyr::select(substance_id, log_dose, response),
  formula = BayesPharma::dr_formula(0 + substance_id), 
  priors = kor_priors2,
  init = BayesPharma::dr_inits())

kor_model2
```
\normalsize

## Comparing the Two Models Using LOO-Comparison:
One way to evaluate the quality of a model is for each data-point, re-fit the model with remaining points, and evaluate the log probability of the point in the posterior distribution. Taking the expectation across all points give the Expected Log Pointwise predictive Density (ELPD). Since this is computationally challenging to re-fit the model for each point, if the model fits the data reasonably well, then the ELPD can be approximated using the Pareto smoothed importance sampling (PSIS). Using the LOO, the package, Pareto k value for each data point is computed, where k less than 0.5 is good, between 0.5 and 0.7 is ok, and higher than 0.7 indicates the data point is not fit by the model well. Evaluating the model for the KOR antagonists, shows that the model fits the data well.

```{r kor-loo}
#| dependson=c("kor-model")
kor_model <- kor_model |>
  brms::add_criterion(criterion = c("loo"), reloo = TRUE)
kor_model$critera$loo
```
Since ELPD is a global measure of model fit, it can be used to compare models. Using `loo_compare` from the LOO package, returns the `elpd_diff` and `se_diff` for each model relative the the model with the lowest ELPD. The kor_model2, the model with more informative priors, is the preferred model, but not significantly.

```{r kor-model-model2-loo-compare}
#| dependson=c("kor-loo", "kor-model2")
kor_model2 <- kor_model2 |>
  brms::add_criterion(criterion = c("loo"), reloo = TRUE)

brms::loo_compare(kor_model, kor_model2)
```

##Analysis Using the drc Package

Here we will analyze the KOR antagonist data using the drc package and compare
it to the results from the BayesPharma analysis. 

We will fix the top to 100 and fit the ic50, hill, and bottom.

\scriptsize
```{r kor-drc-model}
#| dependson=c("kor-data"),
#| echo=TRUE
drc_models <- kor_antag |>
  dplyr::group_by(substance_id) |>
  dplyr::group_nest() |>
  dplyr::mutate(
    model = data |> 
      purrr::map(~drc::drm(
        response ~ log_dose,
        data = .x,
        fct = drc::L.4(fixed = c(NA, NA, 100, NA),
        names = c("hill", "bottom", "top", "ic50")))))

drc_models |>
  dplyr::mutate(summary = purrr::map(model, broom::tidy, conf.int = TRUE)) |>
  tidyr::unnest(summary) |>
  dplyr::arrange(term, substance_id) |>
  dplyr::select(-data, -model, -curve)
```
\normalsize

Displayed below is the comparison of results from `drc` and `BayesPharma` for each parameter of the dose-response curve. Here we see that the Bayesian method provides a distribution curve as evidence and has smaller confidence intervals than most of the standard errors provided by the drc method. 

```{r}
#| dependson = c("kor-drc-model", "kor-model"),
#| fig.width = 9,
#| fig.height = 3,
#| fig.cap="KOR antagonists conditional effects. The blue lines are samples from the BayesPharma kor_model posterior distribution, the orange line is the conditional mean, and the purple line is the conditional mean for the DRC model fit."
drc_model_conditional_effects <- drc_models |>
  dplyr::mutate(
    response = model |> purrr::map(
      predict,
      expand.grid(seq(-11, -6, length.out = 100)))) |>
  tidyr::unnest(response) |>
  dplyr::group_by(substance_id) |>
  dplyr::mutate(
    log_dose = seq(-11, -6, length.out = 100)) |>
  dplyr::ungroup() |>
  dplyr::transmute(
    model_name = "DRC",
    cond__ = substance_id,
    log_dose,
    response)

drc_model_conditional_effects_plot_layers <- list(
  ggplot2::geom_line(
    data = drc_model_conditional_effects,
    mapping = ggplot2::aes(
      x = log_dose,
      y = response),
    color = "purple",
    size = 1.3))

kor_model_conditional_effects <- kor_model |>  
  brms::conditional_effects(
    effects = "log_dose",
    conditions = kor_model |>
      brms::make_conditions(
        vars = "substance_id",
        incl_vars = FALSE),
    spaghetti = TRUE,
    ndraws = 100)

kor_model_conditional_effects_plot <- kor_model_conditional_effects |>
  plot(
    points = TRUE,
    mean = TRUE,
    line_args = list(size = 1.3, colour = "orange"),
    point_args = list(width = 0.02),
    plot = FALSE,
    facet_args = list(nrow = 1, ncol = 4),
    theme = ggplot2::theme_bw()) |>
  purrr::pluck(1)

kor_model_conditional_effects_plot +
  drc_model_conditional_effects_plot_layers +
  ggplot2::scale_x_continuous("log [Dose]") +
  ggplot2::scale_y_continuous("Response")
  
```




## MuSyC synergy model {#MuSyC}
When two independent treatments are combined they may synergize to effect the response. A typical use case is combining to different drugs to determine if there is signaling epistasis or to assess the value of combining them as a combination therapy. Alternatively for ion channels, a drug and voltage can be combined to evaluate the effect on the membrane potential.

When two treatments are combined they can influence each other in different ways. The combine treatment can elicit a stronger or weaker effect than either treatment separately, or in the presence of one drug, the the dose at which the the other effects the outcome may be shifted. These different forms of synergy are modeled by the classical Bliss and Loewe models of synergy, respectively. Recently XXX derived the MuSyC model that combines these different forms of synergy.  

The functional form for the MuSyC model gives an equation for the response $\color{response}{E_d}$ at doses of $\color{dose}{d_1}$ and $\color{dose}{d_2}$ of the two treatments and has $9$ free parameters $\{\color{dose}{C_1}, \color{dose}{C_2}, \color{response}{E_0}, \color{response}{E_1}, \color{response}{E_2}, \color{response}{E_3}, \color{shape}{h_1}, \color{shape}{h_2}, \color{shape}{\alpha}\}$:

\begin{align}
\color{response}{E_d} &= \frac{
          {\color{dose}{C_1}}^{\color{shape}{h_1}}{\color{dose}{C_2}}^{\color{shape}{h_2}}{\color{response}{E_0}} +
          {\color{dose}{d_1}}^{\color{shape}{h_1}}{\color{dose}{C_2}}^{\color{shape}{h_2}}{\color{response}{E_1}} +
          {\color{dose}{C_1}}^{\color{shape}{h_1}}{\color{dose}{d_2}}^{\color{shape}{h_2}}{\color{response}{E_2}} +
          {\color{dose}{d_1}}^{\color{shape}{h_1}}{\color{dose}{d_2}}^{\color{shape}{h_2}}{\color{shape}{\alpha}} {\color{response}{E_3}}
       }{
          {\color{dose}{C_1}}^{\color{shape}{h_1}}{\color{dose}{C_2}}^{\color{shape}{h_2}} +
          {\color{dose}{d_1}}^{\color{shape}{h_1}}{\color{dose}{C_2}}^{\color{shape}{h_2}} +
          {\color{dose}{C_1}}^{\color{shape}{h_1}}{\color{dose}{d_2}}^{\color{shape}{h_2}} +
          {\color{dose}{d_1}}^{\color{shape}{h_1}}{\color{dose}{d_2}}^{\color{shape}{h_2}}{\color{shape}{\alpha}}}
\end{align}

To interpret these parameters if we set $\color{dose}{d_2}=0$, then 
\begin{align}
\color{response}{E_d} &= \frac{
          {\color{dose}{C_1}}^{\color{shape}{h_1}}{\color{response}{E_0}} +
          {\color{dose}{d_1}}^{\color{shape}{h_1}}{\color{response}{E_1}}
       }{
          {\color{dose}{C_1}}^{\color{shape}{h_1}} +
          {\color{dose}{d_1}}^{\color{shape}{h_1}}}
\end{align}
which is the Hill equation, which we modeled above \ref{sec:hill}. If we then additionally set $\color{dose}{d_1}=0$ then $\color{response}{E_d}=\color{response}{E_0}$, in the limit as ${\color{dose}{d_1}}\rightarrow \infty$ then ${\color{response}{E_d}}\rightarrow {\color{response}{E_1}}$, and if ${\color{dose}{d_1}}=\color{dose}{C_1}$ then ${\color{response}{E_d}} = ({\color{response}{E_0}} + {\color{response}{E_2}})/2$, which is the half maximal response (either the $\color{response}{\mbox{IC}_{50}}$ if treatment $1$ is an inhibitor or $\color{response}{\mbox{EC}_{50}}$ if treatment $1$ is agonist). The slope at ${\color{dose}{d_1}}={\color{dose}{C_1}}$ is 
\begin{align*}
    \frac{\mathrm{d}\;\color{response}{E_d}}{\mathrm{d}\color{dose}{d_1}}
        &= {\color{dose}{C_1}}^{v}{\color{response}{E_0}}
              \frac{\mathrm{d}}{\mathrm{d}\color{dose}{d_1}}
                  \frac{1}{{\color{dose}{C_1}}^{\color{shape}{h_1}} + {\color{dose}{d_1}}^{\color{shape}{h_1}}} +
           {\color{response}{E_1}}
              \frac{\mathrm{d}}{\mathrm{d}\color{dose}{d_1}}
                   \frac{{\color{dose}{d_1}}^{h_1}}{{\color{dose}{C_1}}^{\color{shape}{h_1}} + {\color{dose}{d_1}}^{\color{shape}{h_1}}}\\
        &= {\color{dose}{C_1}}^{h_1}{\color{response}{E_0}}
              \frac{                          h_1{\color{dose}{d_1}}^{{\color{shape}{h_1}}-1}}{\left({\color{dose}{C_1}}^{\color{shape}{h_1}} + {\color{dose}{d_1}}^{\color{shape}{h_1}}\right)^2} +
            {\color{response}{E_1}}
               \frac{{\color{dose}{C_1}}^{\color{shape}{h_1}}h_1{\color{dose}{d_1}}^{{\color{shape}{h_1}}-1}}{\left({\color{dose}{C_1}}^{\color{shape}{h_1}} + {\color{dose}{d_1}}^{\color{shape}{h_1}}\right)^2}\\
        &= ({\color{response}{E_0}} + {\color{response}{E_1}})
\end{align*}

The evaluation of the functional form for ${\color{response}{E_d}}$ is numerically unstable. To transform using the $\mbox{log\_sum\_exp}$ trick, let

\begin{align*}
\mbox{numerator\_parts} = [\\
      &{\color{shape}{h_1}}\log({\color{dose}{C_1}}) + {\color{shape}{h_2}}\log({\color{dose}{C_2}}) + \log({\color{response}{E_0}}),\\
      &{\color{shape}{h_1}}\log({\color{dose}{d_1}}) + {\color{shape}{h_2}}\log({\color{dose}{C_2}}) + \log({\color{response}{E_1}}),\\
      &{\color{shape}{h_1}}\log({\color{dose}{C_1}}) + {\color{shape}{h_2}}\log({\color{dose}{d_2}}) + \log({\color{response}{E_2}}),\\
      &{\color{shape}{h_1}}\log({\color{dose}{d_1}}) + {\color{shape}{h_2}}\log({\color{dose}{d_2}}) + \log({\color{response}{E_3}}) + \log({\color{shape}{\alpha}}) ]\\
\mbox{denominator\_parts} = [\\
      &{\color{shape}{h_1}}\log({\color{dose}{C_1}}) + {\color{shape}{h_2}}\log({\color{dose}{C_2}}),\\
      &{\color{shape}{h_1}}\log({\color{dose}{d_1}}) + {\color{shape}{h_2}}\log({\color{dose}{C_2}}),\\
      &{\color{shape}{h_1}}\log({\color{dose}{C_1}}) + {\color{shape}{h_2}}\log({\color{dose}{d_2}}),\\
      &{\color{shape}{h_1}}\log({\color{dose}{d_1}}) + {\color{shape}{h_2}}\log({\color{dose}{d_2}})]\\
\end{align*}
Then 
$$
    E_d = \mbox{exp}\!\left(\mbox{log\_sum\_exp}(\mbox{numerator\_parts}) - \mbox{log\_sum\_exp}(\mbox{denominator\_parts})\right).
$$

## Michaelis-Menten enzyme progress model {#michaelis_menten}

## Model selection {#model_selection}

(Vehtari, 2016, https://arxiv.org/abs/1507.04544)
predictive accuracy
   how well would the model generalize to new data?
   empirical risk minimization of the model log-likelihood
   leave-k-out cross validation
      - expensive to re-fit model k times
      - approximation via importance sampling but may be unstable
      - Pareto smoothed importance sampling (PSIS) more stable



## Over dispersed negative binomial response

The response of an assay results from a measurement of the experimental system. Often the measurements are normalized so that the response for negative control is 1 (e.g. diseased) and the positive control is 0 (e.g. healthy). However when the robustness of the measurement depends on the measured value, this normalization can make it difficult to combine different measurements. An alternative approach is to model the measurements directly, to take into account the uncertainty associated with the response. To illustrate, if the measurement is the relative number of cells having a phenotype, then five out of ten cells and five thousand out of ten thousand cells will have the same response of 0.5, but the former will a less reliable measurement.        

