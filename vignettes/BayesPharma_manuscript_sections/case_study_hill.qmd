## Hill Equation {#hill}
In this case study we are going to reanalyze the dose response of 4 Kappa Opioid 
receptor (KOR) antagonists using the `BayesPharma` package from from a study 
done by Margolis et al. (-@Margolis2020-bm). Whole cell electrophysiology in acute rat midbrain slices was used to evaluate pharmacological properties of four novel KOR antagonists: BTRX-335140, BTRX-395750, PF-04455242, and JNJ-67953964

Originally paper, the dose-response data analysis was done by using the `drc` package in R which implements the minimization of negative log likelihood function and reduces to least square estimation for a continuous response. The data was normalized to % baseline then fit to a 4-parameter log-logistic dose response model, setting the top (max response) to 100% and estimating the IC50, its variance, and the bottom (min response).

### Fitting the sigmoid model
Using the BayesPharma package, we can re-fit the sigmoid model with a negative slope, and fixing the top parameter to 100 as the response is normalized to a no-drug baseline.

For the priors, we are going to use a normal distribution because the response
values are continuous. First, We will run the analysis with top (max response) parameter prior set to a constant value of 100 because top is normalized to 100 and the default broad
priors for ic50, hill and bottom. Broad priors represent unbiased uncertainty and provide an opportunity for extreme responses.

The level of informativeness of the priors will affect how much influence the priors have on the model. Here is more [information on prior choice recommendations.](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)
\scriptsize
```{r kor-priors}
#| echo=TRUE
kor_prior <- BayesPharma::sigmoid_antagonist_prior(top = 100)
kor_prior
```
\normalsize

#### Prior predictive checks
Following the Bayesian workflow, before fitting the model it is good to check
the prior predictive distributions to see if they are compatible with the domain
expertise. So, before running the model, we will verify that the prior
distributions cover a plausible range of values for each parameter. To do this,
we want to  sample only from the prior distributions by adding
*sample_prior = "only"* as  an argument to the `sigmoid_model` function. We will
use the default response distribution of the model  (*family = gaussian()*).


```{r kor-data}
load("/Users/maom/opt/BayesPharma/data/kor_antag.rda")
kor_antag <- kor_antag |> dplyr::transmute(
  substance_id = Drug,
  cell_id = cell_number,
  log_dose = log_dose,
  response = normalized_measurement)
```

\scriptsize
```{r kor-prior-sample}
#| echo=TRUE,
#| results='hide',
#| message=FALSE,
#| dependson=c("kor-priors")

kor_sample_priors <- BayesPharma::sigmoid_antagonist_model(
  data = kor_antag |> dplyr::select(substance_id, log_dose, response),
  priors = kor_priors,
  sample_prior = "only")
```
\normalsize

And then plot of the prior predictive distributions:

\scriptsize
```{r kor-prior-density-plot}
#| echo=TRUE,
#| results='show',
#| dependson=c("kor-prior-sample"),
#| fig.width = 9,
#| fig.height = 2.6,
#| fig.cap="KOR antagonists prior distribution"

kor_sample_priors |>
  bayesplot::mcmc_dens(
    x = kor_sample_priors) +
  ggplot2::theme_bw
  ggplot2::facet_wrap(
    facets = dplyr::vars(.variable),
    scales = "free",
    nrow = 1)

BayesPharma::density_distributions_plot(
  kor_sample_priors, 
  half_max_label = "ic50",
  title_label = "") +
  ggplot2::facet_wrap(
    facets = dplyr::vars(.variable),
    scales = "free",
    nrow = 1)
```
\normalsize

To sample from the model we will the Stan NUTs Hamiltonian Monte Carlo, and initialize the parameters to the prior means to help with model convergence, using the default values of ec50 = -9, hill = -1, top = 100, bottom = 0.

\scriptsize
```{r kor-model}
#| echo=TRUE,
#| dependson = c("kor-data"),
#| results='hide',
#| message=FALSE
kor_model <- BayesPharma::sigmoid_antagoinst_model(
  data = kor_antag |> dplyr::select(substance_id, log_dose, response),
  formula = BayesPharma::sigmoid_antagonistformula(
    predictors = 0 + substance_id), 
  priors = kor_priors)
brms::expose_functions(kor_model, vectorize=TRUE)
```
\normalsize

### Analyzing model fit
The BRMS generated model summary shows the formula that the expected response is sigmoid function of the log_dose with four parameters, and a shared Gaussian distribution. Each parameter is dependent on the substance_id. Since want to fit a separate model for each substance we include a `0 +` to indicate that there is no common intercept.  The consists of 73 data points and the posterior sampling was done in 4 chains each with 8000 steps with 4000 steps of warm-up. The population effects for each parameter summarize marginal posterior distributions, as well as the effective sample size in the bulk and tail. This gives an indication of the sampling quality, with an ESS of > 500 samples being good for this type of model. 
\scriptsize
```{r kor-model-summary}
#| dependson=c("kor-model"),
#| R.options = list(width = 350)
kor_model
```
\normalsize

#### Traceplot
The model ran without warning messages meaning there were no parameter value 
problems or mcmc conflicts. The bulk and tail ESS indicate high resolution and 
stability. The R-hat for each parameter equals 1.00 and the traceplot shows the 
chains mixed well indicating the chains converged.

\scriptsize
```{r kor-model-traceplot}
#| echo=TRUE,
#| fig.height=6,
#| fig.width=12,
#| dependson=c("kor-model")

BayesPharma::traceplot(
  kor_model, 
  predictors_col_name = "substance_id", 
  half_max_label = "ic50") 
```
\normalsize

#### Compare prior and posterior marginal distributions
Displayed below is a plot for the prior and posterior distributions of the  parameters (prior is pink and posterior is teal). this can be useful for  comparing the density distribution of the prior and posterior. produced by the model:

\scriptsize
```{r kor-model-prior-posterior-densities}
#| dependson=c("kor-model"),
#| echo=TRUE,
#| results='hide',
#| message=FALSE,
#| fig.width = 9,
#| fig.height = 5,
#| fig.cap="KOR antagonists model, compare prior and posterior distributions for each substance"

BayesPharma::prior_posterior_densities_plot(
  kor_model,
  predictors_col_name = "substance_id",
  half_max_label = "ic50",
  title_label="")
```
\normalsize
Displayed below is a plot of the posterior distributions for each parameter 
with the confidence intervals and mean. This is a useful visual of the model 
results and to highlight the mode and high density intervals: 
  
```{r kor-model-posterior-densities}
#| dependson=c("kor-model"),
#| echo=TRUE,
#| message=FALSE,
#| warning=FALSE,
#| fig.width=9,
#| fig.height=5,
#| fig.cap="KOR Antagonists, posterior distribution for each substance"

BayesPharma::posterior_densities_plot(
  kor_model, 
  predictors_col_name = "substance_id", 
  half_max_label = "ic50",
  title_label = "")
```

Displayed below is a plot of a sample of 100 sigmoid dose-response curves from 
the posterior distribution (purple) and the median quantile intervals: 

```{r kor-model-posterior-draws}
#| echo=TRUE,
#| results='hide',
#| message=FALSE,
#| warning=FALSE,
#| dependson=c("kor-model"),
#| fig.cap="KOR antagonists, posterior draws"

BayesPharma::posterior_draws_plot(
  model = kor_model,
  predictors_col_name = "substance_id",
  lower = -12,
  upper = -4,
  n = 50, 
  facet_var = substance_id,
  title = "",
  xlab = "Log[Molar]",
  ylab = "Response")
```

### Comparing alternative models

To test the sensitivity of the analysis to the priors, we can re-fit the model with more informative priors:
\scriptsize
```{r kor-model-priors2}
kor_priors2 <- BayesPharma::sigmoid_antagoinst_prior(
  ec50 = brms::prior(normal(-8.5, 0.5), nlpar = "ec50"),
  hill = brms::prior(normal(-1, 0.5), ub = 0.01, nlpar = "hill"),
  top = 100,
  bottom = brms::prior(normal(10, 15), nlpar = "bottom"))
kor_priors2
```
\normalsize

Re-fitting the model

\scriptsize
```{r kor-model2}
#| results='hide',
#| message=FALSE,
#| dependson=c("kor-model-priors2")

kor_model2 <- BayesPharma::sigmoid_antagonist_model(
  data = kor_antag |> dplyr::select(substance_id, log_dose, response),
  formula = BayesPharma::sigmoid_antagoinst_formula(0 + substance_id), 
  priors = kor_priors2)

kor_model2
```
\normalsize

## Comparing the Two Models Using LOO-Comparison:
One way to evaluate the quality of a model is for each data-point, re-fit the model with remaining points, and evaluate the log probability of the point in the posterior distribution. Taking the expectation across all points give the Expected Log Pointwise predictive Density (ELPD). Since this is computationally challenging to re-fit the model for each point, if the model fits the data reasonably well, then the ELPD can be approximated using the Pareto smoothed importance sampling (PSIS). Using the LOO, the package, Pareto k value for each data point is computed, where k less than 0.5 is good, between 0.5 and 0.7 is ok, and higher than 0.7 indicates the data point is not fit by the model well. Evaluating the model for the KOR antagonists, shows that the model fits the data well.

```{r kor-loo}
#| dependson=c("kor-model")
kor_model <- kor_model |>
  brms::add_criterion(criterion = c("loo"), reloo = TRUE)
kor_model$critera$loo
```
Since ELPD is a global measure of model fit, it can be used to compare models. Using `loo_compare` from the LOO package, returns the `elpd_diff` and `se_diff` for each model relative the model with the lowest ELPD. The kor_model2, the model with more informative priors, is the preferred model, but not significantly.

```{r kor-model-model2-loo-compare}
#| dependson=c("kor-loo", "kor-model2")
kor_model2 <- kor_model2 |>
  brms::add_criterion(criterion = c("loo"), reloo = TRUE)

brms::loo_compare(kor_model, kor_model2)
```

##Analysis Using the drc Package

Here we will analyze the KOR antagonist data using the drc package and compare
it to the results from the BayesPharma analysis. 

We will fix the top to 100 and fit the ic50, hill, and bottom.

\scriptsize
```{r kor-drc-model}
#| dependson=c("kor-data"),
#| echo=TRUE
drc_models <- kor_antag |>
  dplyr::group_by(substance_id) |>
  dplyr::group_nest() |>
  dplyr::mutate(
    model = data |> 
      purrr::map(~drc::drm(
        response ~ log_dose,
        data = .x,
        fct = drc::L.4(fixed = c(NA, NA, 100, NA),
        names = c("hill", "bottom", "top", "ic50")))))

drc_models |>
  dplyr::mutate(summary = purrr::map(model, broom::tidy, conf.int = TRUE)) |>
  tidyr::unnest(summary) |>
  dplyr::arrange(term, substance_id) |>
  dplyr::select(-data, -model, -curve)
```
\normalsize

Displayed below is the comparison of results from `drc` and `BayesPharma` for each parameter of the dose-response curve. Here we see that the Bayesian method provides a distribution curve as evidence and has smaller confidence intervals than most of the standard errors provided by the drc method. 

```{r}
#| dependson = c("kor-drc-model", "kor-model"),
#| fig.width = 9,
#| fig.height = 3,
#| fig.cap="KOR antagonists conditional effects. The blue lines are samples from the BayesPharma kor_model posterior distribution, the orange line is the conditional mean, and the purple line is the conditional mean for the DRC model fit."
drc_model_conditional_effects <- drc_models |>
  dplyr::mutate(
    response = model |> purrr::map(
      predict,
      expand.grid(seq(-11, -6, length.out = 100)))) |>
  tidyr::unnest(response) |>
  dplyr::group_by(substance_id) |>
  dplyr::mutate(
    log_dose = seq(-11, -6, length.out = 100)) |>
  dplyr::ungroup() |>
  dplyr::transmute(
    model_name = "DRC",
    cond__ = substance_id,
    log_dose,
    response)

drc_model_conditional_effects_plot_layers <- list(
  ggplot2::geom_line(
    data = drc_model_conditional_effects,
    mapping = ggplot2::aes(
      x = log_dose,
      y = response),
    color = "purple",
    size = 1.3))

kor_model_conditional_effects <- kor_model |>  
  brms::conditional_effects(
    effects = "log_dose",
    conditions = kor_model |>
      brms::make_conditions(
        vars = "substance_id",
        incl_vars = FALSE),
    spaghetti = TRUE,
    ndraws = 100)

kor_model_conditional_effects_plot <- kor_model_conditional_effects |>
  plot(
    points = TRUE,
    mean = TRUE,
    line_args = list(size = 1.3, colour = "orange"),
    point_args = list(width = 0.02),
    plot = FALSE,
    facet_args = list(nrow = 1, ncol = 4),
    theme = ggplot2::theme_bw()) |>
  purrr::pluck(1)

kor_model_conditional_effects_plot +
  drc_model_conditional_effects_plot_layers +
  ggplot2::scale_x_continuous("log [Dose]") +
  ggplot2::scale_y_continuous("Response")
  
```
